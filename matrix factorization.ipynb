{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GogZLbXSPaCP",
        "outputId": "ea030add-2000-4d4a-b386-08271b3a2faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Data Acquisition ---\n",
            "First 5 rows of the dataset:\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "\n",
            "Dataset Summary (info()):\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 15 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   survived     891 non-null    int64   \n",
            " 1   pclass       891 non-null    int64   \n",
            " 2   sex          891 non-null    object  \n",
            " 3   age          714 non-null    float64 \n",
            " 4   sibsp        891 non-null    int64   \n",
            " 5   parch        891 non-null    int64   \n",
            " 6   fare         891 non-null    float64 \n",
            " 7   embarked     889 non-null    object  \n",
            " 8   class        891 non-null    category\n",
            " 9   who          891 non-null    object  \n",
            " 10  adult_male   891 non-null    bool    \n",
            " 11  deck         203 non-null    category\n",
            " 12  embark_town  889 non-null    object  \n",
            " 13  alive        891 non-null    object  \n",
            " 14  alone        891 non-null    bool    \n",
            "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
            "memory usage: 80.7+ KB\n",
            "--------------------------------------------------\n",
            "--- Step 2: Handling Missing Values ---\n",
            "\n",
            "Missing values before handling:\n",
            "survived         0\n",
            "pclass           0\n",
            "sex              0\n",
            "age            177\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         2\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           688\n",
            "embark_town      2\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after Step 2:\n",
            "survived       0\n",
            "pclass         0\n",
            "sex            0\n",
            "age            0\n",
            "sibsp          0\n",
            "parch          0\n",
            "fare           0\n",
            "embarked       2\n",
            "class          0\n",
            "who            0\n",
            "adult_male     0\n",
            "embark_town    0\n",
            "alive          0\n",
            "alone          0\n",
            "dtype: int64\n",
            "--------------------------------------------------\n",
            "--- Step 3: Handling Outliers in Fare ---\n",
            "Fare statistics after outlier handling (IQR method applied):\n",
            "count    891.000000\n",
            "mean      24.046813\n",
            "std       20.481625\n",
            "min        0.000000\n",
            "25%        7.910400\n",
            "50%       14.454200\n",
            "75%       31.000000\n",
            "max       65.634400\n",
            "Name: fare, dtype: float64\n",
            "--------------------------------------------------\n",
            "--- Step 4: Feature Engineering ---\n",
            "Engineered features (first 5 rows):\n",
            "   familysize  isalone\n",
            "0           2        0\n",
            "1           2        0\n",
            "2           1        1\n",
            "3           2        0\n",
            "4           1        1\n",
            "--------------------------------------------------\n",
            "--- Step 5: Categorical Encoding and Column Dropping ---\n",
            "DataFrame columns after encoding and dropping:\n",
            "['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'familysize', 'isalone', 'sex_male', 'embarked_Queenstown', 'embarked_Southampton']\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# --- Step 1: Data Acquisition ---\n",
        "print(\"--- Step 1: Data Acquisition ---\")\n",
        "# Load the inbuilt Titanic dataset\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataset Summary (info()):\")\n",
        "df.info()\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- Step 2: Handling Missing Values ---\n",
        "print(\"--- Step 2: Handling Missing Values ---\")\n",
        "\n",
        "# Identify missing values before handling\n",
        "print(\"\\nMissing values before handling:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Fill missing Age with median value\n",
        "df['age'] = df['age'].fillna(df['age'].median())\n",
        "\n",
        "# Fill missing Embarked (using 'embark_town' which has the missing values) with mode\n",
        "mode_embark_town = df['embark_town'].mode()[0]\n",
        "df['embark_town'] = df['embark_town'].fillna(mode_embark_town)\n",
        "# The 'embarked' column (S, C, Q) is also filled indirectly or by the preceding 'age' fill.\n",
        "\n",
        "# Drop the Cabin column (which is named 'deck' in the seaborn dataset)\n",
        "# Check if 'deck' exists before dropping to avoid KeyError\n",
        "if 'deck' in df.columns:\n",
        "    df.drop('deck', axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"\\n'deck' (Cabin) column not found or already dropped.\")\n",
        "\n",
        "print(\"\\nMissing values after Step 2:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- Step 3: Handling Outliers in Fare ---\n",
        "print(\"--- Step 3: Handling Outliers in Fare ---\")\n",
        "\n",
        "# Detect outliers in Fare using the IQR method\n",
        "Q1 = df['fare'].quantile(0.25)\n",
        "Q3 = df['fare'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Replace extreme Fare values with capping (winsorizing)\n",
        "df['fare'] = np.where(df['fare'] > upper_bound, upper_bound, df['fare'])\n",
        "df['fare'] = np.where(df['fare'] < lower_bound, lower_bound, df['fare'])\n",
        "\n",
        "print(\"Fare statistics after outlier handling (IQR method applied):\")\n",
        "print(df['fare'].describe())\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- Step 4: Feature Engineering ---\n",
        "print(\"--- Step 4: Feature Engineering ---\")\n",
        "\n",
        "# FIX: Extract Title from the 'name' column (not 'who', which caused the IndexError)\n",
        "# Format is 'LastName, Title. FirstName'\n",
        "# The 'name' column was dropped earlier, so this step is removed\n",
        "# df['title'] = df['name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
        "\n",
        "\n",
        "# Create FamilySize = SibSp + Parch + 1\n",
        "df['familysize'] = df['sibsp'] + df['parch'] + 1\n",
        "\n",
        "# Create IsAlone = 1 if FamilySize = 1, else 0\n",
        "df['isalone'] = np.where(df['familysize'] == 1, 1, 0)\n",
        "\n",
        "# Print engineered features, excluding 'name' as it was dropped\n",
        "print(\"Engineered features (first 5 rows):\")\n",
        "print(df[['familysize', 'isalone']].head()) # 'title' is not created here\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# --- Step 5: Categorical Encoding and Column Dropping ---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 5: Categorical Encoding and Column Dropping ---\")\n",
        "\n",
        "columns_to_drop = ['name', 'embarked', 'class', 'who', 'adult_male', 'alive', 'alone', 'ticket', 'title']\n",
        "df.drop(columns_to_drop, axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "print(\"DataFrame columns after encoding and dropping:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjXVrib_PoQU",
        "outputId": "363ab432-40ad-4dc9-b2d2-12cc28c27e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 5: Categorical Encoding and Column Dropping ---\n",
            "DataFrame columns after encoding and dropping:\n",
            "['survived', 'pclass', 'age', 'sibsp', 'parch', 'fare', 'familysize', 'isalone', 'sex_male', 'embarked_Queenstown', 'embarked_Southampton']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 6: Dimensionality Reduction (PCA) ---\")\n",
        "\n",
        "pca_features = ['age', 'fare', 'familysize']\n",
        "\n",
        "X_pca = df[pca_features].copy()\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_pca)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principal_components = pca.fit_transform(X_scaled)\n",
        "pca_df = pd.DataFrame(data = principal_components,\n",
        "                      columns = ['principal_component_1', 'principal_component_2'])\n",
        "\n",
        "print(f\"PCA Explained Variance Ratio: {pca.explained_variance_ratio_.sum():.2f}\")\n",
        "print(\"New PCA feature structure (first 5 rows):\")\n",
        "print(pca_df.head())\n",
        "\n",
        "df.drop(pca_features, axis=1, inplace=True)\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbJVSSChQGvv",
        "outputId": "c63c0bae-ed33-4a02-e76b-acd8be6c77ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 6: Dimensionality Reduction (PCA) ---\n",
            "PCA Explained Variance Ratio: 0.84\n",
            "New PCA feature structure (first 5 rows):\n",
            "   principal_component_1  principal_component_2\n",
            "0              -0.332650              -0.904528\n",
            "1               1.152268               1.582672\n",
            "2              -0.847205              -0.532609\n",
            "3               0.825513               1.077084\n",
            "4              -1.008120               0.057714\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 7: Data Cleaning ---\")\n",
        "\n",
        "initial_rows = len(df)\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(f\"Removed {initial_rows - len(df)} duplicate rows.\")\n",
        "\n",
        "if df.isnull().sum().sum() == 0:\n",
        "    print(\"Data Cleaning: No missing values remain in the processed DataFrame.\")\n",
        "else:\n",
        "    print(f\"WARNING: {df.isnull().sum().sum()} missing values found.\")\n",
        "\n",
        "print(\"Column types (dtypes):\")\n",
        "print(df.dtypes)\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWDHCEj-QZrg",
        "outputId": "25992147-85a8-4cfc-d727-607dbf66c143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 7: Data Cleaning ---\n",
            "Removed 731 duplicate rows.\n",
            "Data Cleaning: No missing values remain in the processed DataFrame.\n",
            "Column types (dtypes):\n",
            "survived                int64\n",
            "pclass                  int64\n",
            "sibsp                   int64\n",
            "parch                   int64\n",
            "isalone                 int64\n",
            "sex_male                 bool\n",
            "embarked_Queenstown      bool\n",
            "embarked_Southampton     bool\n",
            "dtype: object\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Step 8: Final Dataset ---\")\n",
        "\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "final_df = pd.concat([df, pca_df], axis=1)\n",
        "\n",
        "y = final_df['survived']\n",
        "X = final_df.drop('survived', axis=1)\n",
        "\n",
        "print(\"Final Feature Matrix (X) - first 5 rows:\")\n",
        "print(X.head())\n",
        "print(f\"\\nShape of the final feature matrix X: {X.shape}\")\n",
        "print(f\"Shape of the target vector y: {y.shape}\")\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LL7B5t02QprR",
        "outputId": "5547d089-9530-4c37-e8fb-74e6016ff09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 8: Final Dataset ---\n",
            "Final Feature Matrix (X) - first 5 rows:\n",
            "   pclass  sibsp  parch  isalone sex_male embarked_Queenstown  \\\n",
            "0     3.0    1.0    0.0      0.0     True               False   \n",
            "1     1.0    1.0    0.0      0.0    False               False   \n",
            "2     3.0    0.0    0.0      1.0    False               False   \n",
            "3     1.0    1.0    0.0      0.0    False               False   \n",
            "4     3.0    0.0    0.0      1.0     True               False   \n",
            "\n",
            "  embarked_Southampton  principal_component_1  principal_component_2  \n",
            "0                 True              -0.332650              -0.904528  \n",
            "1                False               1.152268               1.582672  \n",
            "2                 True              -0.847205              -0.532609  \n",
            "3                 True               0.825513               1.077084  \n",
            "4                 True              -1.008120               0.057714  \n",
            "\n",
            "Shape of the final feature matrix X: (891, 9)\n",
            "Shape of the target vector y: (891,)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import lu\n",
        "\n",
        "print(\"LU Decomposition \")\n",
        "\n",
        "A = np.array([[4, 3],\n",
        "              [6, 3]])\n",
        "\n",
        "P, L, U = lu(A)\n",
        "\n",
        "print(\"Matrix A:\\n\", A)\n",
        "print(\"\\nPermutation matrix (P):\\n\", P)\n",
        "print(\"\\nLower triangular matrix (L):\\n\", L)\n",
        "print(\"\\nUpper triangular matrix (U):\\n\", U)\n",
        "\n",
        "A_reconstructed = P @ L @ U\n",
        "print(\"\\nReconstructed A (P @ L @ U):\\n\", A_reconstructed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27lqLpb8Rok_",
        "outputId": "aeeb80c3-b2c4-4887-a704-bd0a6c5e2071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LU Decomposition \n",
            "Matrix A:\n",
            " [[4 3]\n",
            " [6 3]]\n",
            "\n",
            "Permutation matrix (P):\n",
            " [[0. 1.]\n",
            " [1. 0.]]\n",
            "\n",
            "Lower triangular matrix (L):\n",
            " [[1.         0.        ]\n",
            " [0.66666667 1.        ]]\n",
            "\n",
            "Upper triangular matrix (U):\n",
            " [[6. 3.]\n",
            " [0. 1.]]\n",
            "\n",
            "Reconstructed A (P @ L @ U):\n",
            " [[4. 3.]\n",
            " [6. 3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"\\n QR Decomposition \")\n",
        "\n",
        "A = np.array([[1, 1, 0],\n",
        "              [1, 0, 1],\n",
        "              [0, 1, 1]], dtype=float)\n",
        "\n",
        "Q, R = np.linalg.qr(A)\n",
        "\n",
        "print(\"Matrix A:\\n\", A)\n",
        "print(\"\\nOrthogonal matrix (Q):\\n\", Q)\n",
        "print(\"\\nUpper triangular matrix (R):\\n\", R)\n",
        "\n",
        "A_reconstructed = Q @ R\n",
        "print(\"\\nReconstructed A (Q @ R):\\n\", A_reconstructed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjgesO9-RwjD",
        "outputId": "ce17de54-27c9-4dd5-966d-7c25f97aaabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " QR Decomposition \n",
            "Matrix A:\n",
            " [[1. 1. 0.]\n",
            " [1. 0. 1.]\n",
            " [0. 1. 1.]]\n",
            "\n",
            "Orthogonal matrix (Q):\n",
            " [[-0.70710678  0.40824829 -0.57735027]\n",
            " [-0.70710678 -0.40824829  0.57735027]\n",
            " [-0.          0.81649658  0.57735027]]\n",
            "\n",
            "Upper triangular matrix (R):\n",
            " [[-1.41421356 -0.70710678 -0.70710678]\n",
            " [ 0.          1.22474487  0.40824829]\n",
            " [ 0.          0.          1.15470054]]\n",
            "\n",
            "Reconstructed A (Q @ R):\n",
            " [[ 1.00000000e+00  1.00000000e+00 -1.98977135e-16]\n",
            " [ 1.00000000e+00 -1.78835871e-16  1.00000000e+00]\n",
            " [ 0.00000000e+00  1.00000000e+00  1.00000000e+00]]\n"
          ]
        }
      ]
    }
  ]
}